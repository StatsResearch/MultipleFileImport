---
title: "MultipleFileImport"
author: "Rob Donald"
date: "`r format(Sys.time(), '%A %d %B %Y, %H:%M')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
params:
  dataprep: true
header-includes: \usepackage{comment}
---
<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>


# Introduction

I am often asked if I can combine a number of .csv files into one file.
This project shows some examples and some of the problems.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.height=8,fig.width=12)
options(width=1500)
```

# Cross platform operation

Demo the techniques I use to cope with Windows support.

```{r system_setup, echo=FALSE}
os.type<-Sys.info()[1]
if(os.type == 'Windows'){TLC_Root<-'C:/PostDocStuff'}else{TLC_Root<-'/Users/rob/PostDocStuff/teaching/RStuff'}
```

# Conditional markdown text

`r if(!params$dataprep) {"\\begin{comment}"}`
## Libraries
`r if(!params$dataprep) {"\\end{comment}"}`

```{r library_setup,include=params$dataprep}
suppressMessages({suppressWarnings({
    library(dplyr)
    library(tidyr)
    library(readr)
    
    library(ggplot2)
    library(ggpmisc)
    library(grid)
    library(gridExtra)
    
    library(RobsRUtils)
    library(futile.logger)
    
    library(data.table)
    library(microbenchmark)
    library(gtools)
})})
```

# Background

This project contains several dummy .csv files

File: File_2_Date_02.csv has a duplicate column heading. The techniques seem to cope.

## Data Source

Let's read in all the files using the default settings for dir()

```{r}
all.files <- dir(path = '.',pattern = 'File.*.csv')
all.files
```

# Digging deeper - recursive search

```{r}
all.files.recursive <- dir(path = '.',pattern = 'File.*.csv',  recursive = TRUE,include.dirs = TRUE)
all.files.recursive
```


# Reading a single column from each file

See https://stackoverflow.com/questions/19743271/quicker-way-to-read-single-column-of-csv-file

fread() is from the data.table package. 

fread() is supposed to be *very* fast. Not an issue in these examples but in real life it probably
is something you should consider.

## Using a for() loop

This is nice and easy to understand but not very efficient. In this example I'm reading the 
single column 'Status'.

In the fread() call, the option, data.table = FALSE, makes it return a data.frame rather than a data.table.

```{r}
num.files <- length(all.files)

all.data.info <- NULL

for(file.count in 1:num.files)
{
    file.to.read <- all.files[file.count]
    
    single.column <- fread(input = file.to.read,sep = ",", select = c("Status"),data.table = FALSE ) 
    
    FailCount <- length(single.column[single.column == 'F'])
    PassCount <- length(single.column[single.column == 'P'])
    
    file.res <- data_frame(filename = file.to.read,FailCount,PassCount)
    
    if(is.null(all.data.info))
    {
      all.data.info <- file.res  
    }
    else
    {
      all.data.info <- bind_rows(all.data.info,file.res)  
    }
    
}

all.data.info
```

## Using lapply

This is a vectorised operation and more in the R style.

First we need the function that lapply() will use

```{r}
GetFileColumn<-function(file.to.read)
{
    single.column <- fread(input = file.to.read,sep = ",", select = c("Status"),data.table = FALSE ) 
    
    FailCount <- length(single.column[single.column == 'F'])
    PassCount <- length(single.column[single.column == 'P'])
    
    file.res <- data_frame(filename = file.to.read,FailCount,PassCount)
    
    return(file.res)
}
```

Now use the function. This is a one liner.

```{r}
all.file.results <- lapply(all.files,GetFileColumn)


class(all.file.results)
all.file.results
```
This returns a list with each list element being a data_frame. Let's pick one out
and have a look.

```{r}
single.list.element <- all.file.results[[2]]
single.list.element
class(single.list.element)
```

What you probably want is a single data_frame with each row being a result from a single file.
Luckily the data.table package has a function called rbindlist() which will do that.

```{r}
all.file.results.df <- rbindlist(all.file.results)
all.file.results.df
```

## Export results
We can now, of course, write these results out to a .csv file

```{r}
output.file <- 'ExportedResults.csv'
write_csv(all.file.results.df,path = output.file)
```


# Using readr::read_csv

Let's do the lapply() technique but use read_csv from the readr package. I would 
have thought this must be slower as it is reading *all* the columns then using select()
to pick out the one you want. But is it easier to follow?

```{r}
GetSingleFileColumn<-function(file.to.read)
{
    raw.data <- read_csv(file = file.to.read) 
    single.column <- select(raw.data,Status)
    
    FailCount <- length(single.column$Status[single.column$Status == 'F'])
    PassCount <- length(single.column$Status[single.column$Status == 'P'])
    
    file.res <- data_frame(filename = file.to.read,FailCount,PassCount)
    
    return(file.res)
}
```

```{r}
all.file.results.2 <- lapply(all.files,GetSingleFileColumn)
all.file.results.2.df <- rbindlist(all.file.results.2)
all.file.results.2.df
```

# Performance Timing

We'll now create a large number of files and do some performance timing. I'll use the R package
microbenchmark to do the timing.

```{r}
Big.data.dir <- paste0(TLC_Root,'/MultipleFileImport/BigDataDir')
dir.create(Big.data.dir, showWarnings = FALSE)

units <- seq(1,10)
tens <- seq(10,100,by=10)
days <- rep(c('Mon','Tues','Weds','Thu','Fri'),2)

test.df <- data_frame(days,units,tens)

num.test.files <- 100

for(count in 1:num.test.files)
{
    test.file.full.path <- paste0(Big.data.dir,'/','Test_Data_File_',count,'.csv') 
    write_csv(test.df,path = test.file.full.path)
}
```

Now let's 'discover' them with dir()

```{r}
all.test.files.raw <- dir(path = Big.data.dir)
head(all.test.files.raw,n=10)
```

Note the tedious alphabetical ordering with the first three elements being 1,10,100.

Have a look at this link for a good discussion.

https://stackoverflow.com/questions/17531403/how-to-sort-a-character-vector-where-elements-contain-letters-and-numbers-in-r

We can easily sort it using the mixedsort() function from the R package gtools.
```{r}
all.test.files <- mixedsort(all.test.files.raw)
head(all.test.files,n=11)
```

